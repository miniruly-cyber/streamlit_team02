# Requirements (install first):
#   pip install streamlit python-docx reportlab langchain langchain-openai python-dotenv

import os, io, json, time, textwrap, re, datetime, urllib.parse
import streamlit as st
from typing import Optional, Tuple

# ===== LangChain imports (ì¡°ê±´ë¶€) =====
try:
    from langchain_openai import ChatOpenAI
    from langchain.prompts import ChatPromptTemplate
    from langchain.memory import ConversationBufferMemory
    from langchain.chains import LLMChain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    st.warning("LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install langchain langchain-openai ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

# ================= ê¸°ë³¸ ì„¤ì • =================
st.set_page_config(page_title="ìê¸°ì†Œê°œì„œ ì½”ì¹˜ (LangChain)", page_icon="ğŸ’¬", layout="wide")

# ëª¨ë°”ì¼ ì¹œí™”ì  ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
.main .block-container {
    max-width: 800px;
    padding-top: 1rem;
    padding-bottom: 1rem;
}

.round-header {
    margin: 12px 0 8px;
    background: linear-gradient(135deg, #0FBDBD, #099494);
    color: #fff;
    border-radius: 18px;
    padding: 14px 18px;
    box-shadow: 0 8px 20px rgba(0,0,0,.08);
}

.round-header__title {
    font-weight: 900;
    letter-spacing: .2px;
    margin: 0;
    font-size: 1.2em;
}

.round-header__sub {
    opacity: .95;
    font-size: 0.9em;
    margin-top: 4px;
}

.bubble {
    margin: 10px 0;
    display: flex;
}

.bubble.bot {
    justify-content: flex-start;
}

.bubble.me {
    justify-content: flex-end;
}

.bubble-content {
    max-width: 70%;
}

.bubble-text {
    padding: 10px 14px;
    border-radius: 18px;
    word-wrap: break-word;
    line-height: 1.5;
}

.bubble.bot .bubble-text {
    background: #F3F4F6;
    border-radius: 18px 18px 18px 4px;
}

.bubble.me .bubble-text {
    background: #E8FDFC;
    border-radius: 18px 18px 4px 18px;
}

.bubble-time {
    font-size: 11px;
    color: #64748b;
    margin-top: 4px;
    padding: 0 14px;
}

.chat-container {
    height: 400px;
    overflow-y: auto;
    padding: 10px;
    background: white;
    border-radius: 10px;
    margin-bottom: 20px;
}

/* íƒ­ ìŠ¤íƒ€ì¼ ê°œì„  */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
}

.stTabs [data-baseweb="tab"] {
    height: 50px;
    padding-left: 20px;
    padding-right: 20px;
    background-color: white;
    border-radius: 10px;
}

.stTabs [aria-selected="true"] {
    background-color: #0FBDBD;
    color: white;
}
</style>
""", unsafe_allow_html=True)

# ================= ìƒíƒœ ì´ˆê¸°í™” =================
if "initialized" not in st.session_state:
    st.session_state.initialized = True
    st.session_state.msgs = []
    st.session_state.settings = {
        "provider": "openai",
        "model": "gpt-4o-mini",
        "tone": "ì •ì¤‘í•˜ê³  ê°„ê²°í•œ",
        "length": 800,
        "temperature": 0.7,
        "openai_key": os.getenv("OPENAI_API_KEY", ""),
        "gemini_key": os.getenv("GEMINI_API_KEY", ""),
        "save_dir": os.path.expanduser("~/AI_CoverLetter_Storage")
    }
    # ì´ˆê¸° ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.msgs.append({
        "role": "bot",
        "content": "ì•ˆë…•í•˜ì„¸ìš”! ìê¸°ì†Œê°œì„œ ì‘ì„±ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì–´ë–¤ íšŒì‚¬/ì§ë¬´ì— ì§€ì›í•˜ì‹œë‚˜ìš”?",
        "timestamp": datetime.datetime.now().strftime("%p %I:%M")
    })

# ===== LangChain ë©”ëª¨ë¦¬ ì„¤ì • =====
if LANGCHAIN_AVAILABLE and "lc_memory" not in st.session_state:
    st.session_state.lc_memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# ================= ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ =================
def now_hhmm():
    return datetime.datetime.now().strftime("%p %I:%M").replace("AM", "ì˜¤ì „").replace("PM", "ì˜¤í›„")

def timestamp():
    return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

def slugify(name: str) -> str:
    return (re.sub(r'[\\/:*?"<>|]', "_", name).strip() or "coverletter")

def header_card(title: str, subtitle: str = ""):
    st.markdown(f"""
    <div class="round-header">
      <div class="round-header__title">{title}</div>
      {f'<div class="round-header__sub">{subtitle}</div>' if subtitle else ''}
    </div>""", unsafe_allow_html=True)

# ================= AI ì±—ë´‡ ë¡œì§ =================
def get_ai_response(user_message: str) -> str:
    """LangChainì„ ì‚¬ìš©í•œ AI ì‘ë‹µ ìƒì„±"""
    if not LANGCHAIN_AVAILABLE:
        return "LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ì¤‘ì…ë‹ˆë‹¤.\n\nìê¸°ì†Œê°œì„œ ì‘ì„± íŒ: êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ì„±ê³¼ë¥¼ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”."
    
    try:
        settings = st.session_state.settings
        
        # OpenAI API í‚¤ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹¤ì œ API í˜¸ì¶œ
        if settings["openai_key"]:
            llm = ChatOpenAI(
                api_key=settings["openai_key"],
                model=settings["model"],
                temperature=settings["temperature"]
            )
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", f"""
                ë‹¹ì‹ ì€ ìê¸°ì†Œê°œì„œ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” ì „ë¬¸ ì½”ì¹˜ì…ë‹ˆë‹¤.
                - í†¤: {settings["tone"]}
                - ëª©í‘œ ê¸¸ì´: ì•½ {settings["length"]}ì
                - êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
                - ì‚¬ìš©ìì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì„ ì ì„ ì œì•ˆí•˜ì„¸ìš”
                """),
                ("human", "{input}")
            ])
            
            chain = LLMChain(llm=llm, prompt=prompt, memory=st.session_state.lc_memory)
            response = chain.run(input=user_message)
            return response
        else:
            # ë°ëª¨ ì‘ë‹µ (API í‚¤ê°€ ì—†ì„ ë•Œ)
            demo_responses = {
                "ë§ˆì¼€íŒ…": "ë§ˆì¼€íŒ… ì§ë¬´ ìê¸°ì†Œê°œì„œì—ì„œëŠ” ë°ì´í„° ë¶„ì„ ëŠ¥ë ¥, ì°½ì˜ì„±, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤í‚¬ì„ ê°•ì¡°í•˜ì„¸ìš”. íŠ¹íˆ ìº í˜ì¸ ì„±ê³¼ë¥¼ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¡œ ì œì‹œí•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤.",
                "ê°œë°œ": "ê°œë°œ ì§ë¬´ì—ì„œëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ê¸°ìˆ  ìŠ¤íƒ, í”„ë¡œì íŠ¸ ê²½í—˜, ë¬¸ì œ í•´ê²° ì‚¬ë¡€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.",
                "ì˜ì—…": "ì˜ì—… ì§ë¬´ëŠ” ëª©í‘œ ë‹¬ì„±ë¥ , ê³ ê° ê´€ê³„ ê´€ë¦¬, í˜‘ìƒ ëŠ¥ë ¥ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.",
                "default": "ìê¸°ì†Œê°œì„œ ì‘ì„± ì‹œ STAR ê¸°ë²•(Situation-Task-Action-Result)ì„ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ê²½í—˜ì„ ì„œìˆ í•˜ì„¸ìš”."
            }
            
            for keyword, response in demo_responses.items():
                if keyword in user_message:
                    return f"[ë°ëª¨ ëª¨ë“œ]\n\n{response}\n\nì‹¤ì œ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì • íƒ­ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
            
            return f"[ë°ëª¨ ëª¨ë“œ]\n\n{demo_responses['default']}\n\nì‹¤ì œ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì • íƒ­ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
            
    except Exception as e:
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ================= ë©”ì¸ UI í•¨ìˆ˜ë“¤ =================
def render_chat_tab():
    """ì±„íŒ… íƒ­ ë Œë”ë§"""
    header_card("ğŸ’¬ AI ìê¸°ì†Œê°œì„œ ì½”ì¹˜", "ê°œì¸ë§ì¶¤í˜• ìê¸°ì†Œê°œì„œ ì‘ì„± ë„ìš°ë¯¸")
    
    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­
    chat_container = st.container()
    with chat_container:
        for msg in st.session_state.msgs:
            bubble_class = "bot" if msg["role"] == "bot" else "me"
            
            html_content = f"""
            <div class="bubble {bubble_class}">
                <div class="bubble-content">
                    <div class="bubble-text">{msg["content"]}</div>
                    <div class="bubble-time">{msg.get("timestamp", now_hhmm())}</div>
                </div>
            </div>
            """
            st.markdown(html_content, unsafe_allow_html=True)
    
    # ì…ë ¥ ì˜ì—­
    st.markdown("---")
    
    with st.form(key="chat_form", clear_on_submit=True):
        col1, col2 = st.columns([5, 1])
        with col1:
            user_input = st.text_input(
                "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", 
                placeholder="ì˜ˆ: ë§ˆì¼€íŒ… ì§ë¬´ ìê¸°ì†Œê°œì„œ ì‘ì„±ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                label_visibility="collapsed"
            )
        with col2:
            submit = st.form_submit_button("ì „ì†¡", use_container_width=True, type="primary")
        
        if submit and user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.msgs.append({
                "role": "user",
                "content": user_input,
                "timestamp": now_hhmm()
            })
            
            # AI ì‘ë‹µ ìƒì„±
            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                ai_response = get_ai_response(user_input)
                st.session_state.msgs.append({
                    "role": "bot",
                    "content": ai_response,
                    "timestamp": now_hhmm()
                })
            
            st.rerun()

def render_settings_tab():
    """ì„¤ì • íƒ­ ë Œë”ë§"""
    header_card("âš™ï¸ ì„¤ì •", "AI ëª¨ë¸ ë° ì‘ë‹µ ì„¤ì •")
    
    settings = st.session_state.settings
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ”‘ API í‚¤ ì„¤ì •")
        new_key = st.text_input(
            "OpenAI API Key", 
            value=settings["openai_key"], 
            type="password", 
            help="gpt-4o-mini ëª¨ë¸ ì‚¬ìš©ì„ ìœ„í•œ API í‚¤"
        )
        
        st.subheader("ğŸ¤– ëª¨ë¸ ì„¤ì •")
        new_model = st.selectbox(
            "ëª¨ë¸ ì„ íƒ", 
            ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"], 
            index=["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"].index(settings["model"])
        )
        new_temp = st.slider("ì°½ì˜ì„± ìˆ˜ì¤€", 0.0, 1.0, settings["temperature"], 0.1)
    
    with col2:
        st.subheader("ğŸ“ ì‘ë‹µ ì„¤ì •")
        new_tone = st.selectbox(
            "ì‘ë‹µ í†¤", 
            ["ì •ì¤‘í•˜ê³  ê°„ê²°í•œ", "ì¹œê·¼í•˜ê³  ìƒì„¸í•œ", "ì „ë¬¸ì ì´ê³  ê²©ì‹ìˆëŠ”"],
            index=["ì •ì¤‘í•˜ê³  ê°„ê²°í•œ", "ì¹œê·¼í•˜ê³  ìƒì„¸í•œ", "ì „ë¬¸ì ì´ê³  ê²©ì‹ìˆëŠ”"].index(settings["tone"])
        )
        new_length = st.slider("ëª©í‘œ ì‘ë‹µ ê¸¸ì´ (ì)", 200, 2000, settings["length"], 100)
    
    if st.button("ì„¤ì • ì €ì¥", use_container_width=True, type="primary"):
        st.session_state.settings["openai_key"] = new_key
        st.session_state.settings["model"] = new_model
        st.session_state.settings["temperature"] = new_temp
        st.session_state.settings["tone"] = new_tone
        st.session_state.settings["length"] = new_length
        st.success("âœ… ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

def render_storage_tab():
    """ì €ì¥ì†Œ íƒ­ ë Œë”ë§"""
    header_card("ğŸ’¾ ëŒ€í™” ê¸°ë¡", "ì‘ì„±í•œ ìê¸°ì†Œê°œì„œ ê´€ë¦¬")
    
    if len(st.session_state.msgs) > 1:
        st.subheader("ğŸ“‹ í˜„ì¬ ëŒ€í™” ë‚´ìš©")
        
        # ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        conversation_text = ""
        for msg in st.session_state.msgs:
            if msg["role"] == "user":
                conversation_text += f"ğŸ‘¤ ì‚¬ìš©ì: {msg['content']}\n\n"
            else:
                conversation_text += f"ğŸ¤– AI ì½”ì¹˜: {msg['content']}\n\n"
            conversation_text += "---\n\n"
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.download_button(
            label="ğŸ’¾ ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œ (TXT)",
            data=conversation_text,
            file_name=f"ìê¸°ì†Œê°œì„œ_ìƒë‹´_{timestamp()}.txt",
            mime="text/plain"
        )
        
        # ëŒ€í™” ë‚´ìš© í‘œì‹œ
        with st.expander("ëŒ€í™” ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°", expanded=True):
            st.text_area("", value=conversation_text, height=400, disabled=True)
        
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”", type="secondary"):
            st.session_state.msgs = [{
                "role": "bot",
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ìê¸°ì†Œê°œì„œ ì‘ì„±ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì–´ë–¤ íšŒì‚¬/ì§ë¬´ì— ì§€ì›í•˜ì‹œë‚˜ìš”?",
                "timestamp": now_hhmm()
            }]
            if LANGCHAIN_AVAILABLE:
                st.session_state.lc_memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
            st.success("ëŒ€í™” ë‚´ìš©ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    else:
        st.info("ì•„ì§ ì €ì¥ëœ ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ì±„íŒ… íƒ­ì—ì„œ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”!")

# ================= ë©”ì¸ ì•± ë¡œì§ =================
def main():
    """ë©”ì¸ ì•± ì‹¤í–‰"""
    
    # ì•± ì œëª©
    st.title("ğŸ“± AI ìê¸°ì†Œê°œì„œ ì½”ì¹˜")
    st.caption("LangChain ê¸°ë°˜ ë§ì¶¤í˜• ìê¸°ì†Œê°œì„œ ì‘ì„± ë„ìš°ë¯¸")
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ ì±„íŒ…", "âš™ï¸ ì„¤ì •", "ğŸ’¾ ëŒ€í™” ê¸°ë¡"])
    
    with tab1:
        render_chat_tab()
    
    with tab2:
        render_settings_tab()
    
    with tab3:
        render_storage_tab()
    
    # í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    st.caption("ğŸ’¡ Tip: OpenAI API í‚¤ê°€ ì—†ì–´ë„ ë°ëª¨ ëª¨ë“œë¡œ ê¸°ë³¸ ê¸°ëŠ¥ì„ ì²´í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ================= ì•± ì‹¤í–‰ =================
if __name__ == "__main__":
    main()
