# Requirements (install first):
#   pip install streamlit python-docx reportlab langchain langchain-openai langchain-google-genai python-dotenv googletrans

import os, io, json, time, textwrap, re, datetime, urllib.parse
import streamlit as st
from typing import Optional, Tuple, List, Dict
import base64

# ===== ë¬¸ì„œ ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ =====
try:
    from docx import Document
    from reportlab.lib.pagesizes import letter
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    DOC_LIBS_AVAILABLE = True
except ImportError:
    DOC_LIBS_AVAILABLE = False

# ===== LangChain imports (ì¡°ê±´ë¶€) =====
try:
    from langchain_openai import ChatOpenAI
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain.prompts import ChatPromptTemplate
    from langchain.memory import ConversationBufferMemory
    from langchain.chains import LLMChain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False

# ===== ë²ˆì—­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ =====
try:
    from googletrans import Translator
    TRANSLATOR_AVAILABLE = True
except ImportError:
    TRANSLATOR_AVAILABLE = False

# ================= ê¸°ë³¸ ì„¤ì • =================
st.set_page_config(
    page_title="AI ìê¸°ì†Œê°œì„œ ì½”ì¹˜",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ê°œì„ ëœ ìŠ¤íƒ€ì¼
st.markdown("""
<style>
.main .block-container {
    max-width: 900px;
    padding: 2rem 1rem;
}

.header-container {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border-radius: 20px;
    padding: 2rem;
    margin-bottom: 2rem;
    text-align: center;
    color: white;
    box-shadow: 0 10px 30px rgba(0,0,0,0.1);
}

.header-title {
    font-size: 2.5rem;
    font-weight: 800;
    margin-bottom: 0.5rem;
}

.header-subtitle {
    font-size: 1.1rem;
    opacity: 0.9;
    font-weight: 300;
}

.chat-container {
    background: white;
    border-radius: 20px;
    padding: 1.5rem;
    margin-bottom: 1rem;
    box-shadow: 0 5px 20px rgba(0,0,0,0.05);
    border: 1px solid #f0f0f0;
    height: 500px;
    overflow-y: auto;
}

.message-bubble {
    margin: 1rem 0;
    display: flex;
    align-items: flex-start;
}

.message-bubble.user {
    justify-content: flex-end;
}

.message-bubble.bot {
    justify-content: flex-start;
}

.message-content {
    max-width: 75%;
    padding: 1rem 1.5rem;
    border-radius: 20px;
    font-size: 0.95rem;
    line-height: 1.6;
    word-wrap: break-word;
}

.message-bubble.user .message-content {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-bottom-right-radius: 5px;
}

.message-bubble.bot .message-content {
    background: #f8fafc;
    color: #1a202c;
    border: 1px solid #e2e8f0;
    border-bottom-left-radius: 5px;
}

.stTabs [data-baseweb="tab-list"] {
    gap: 0.5rem;
    background: #f8fafc;
    padding: 0.5rem;
    border-radius: 15px;
}

.stTabs [data-baseweb="tab"] {
    height: 3rem;
    padding: 0 1.5rem;
    background: white;
    border-radius: 10px;
    border: none;
    font-weight: 500;
}

.stTabs [aria-selected="true"] {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
}

.feature-card {
    background: white;
    border-radius: 15px;
    padding: 1.5rem;
    margin: 1rem 0;
    box-shadow: 0 5px 15px rgba(0,0,0,0.05);
    border: 1px solid #e2e8f0;
}

.guideline-card {
    background: linear-gradient(135deg, #e0f2f1 0%, #f3e5f5 100%);
    border-radius: 15px;
    padding: 1.5rem;
    margin: 1rem 0;
    border-left: 4px solid #667eea;
}

.guideline-item {
    background: white;
    border-radius: 10px;
    padding: 1rem;
    margin: 0.5rem 0;
    box-shadow: 0 2px 8px rgba(0,0,0,0.05);
}

.file-item {
    background: white;
    border-radius: 10px;
    padding: 1rem;
    margin: 0.5rem 0;
    box-shadow: 0 2px 8px rgba(0,0,0,0.05);
    border: 1px solid #e2e8f0;
}
</style>
""", unsafe_allow_html=True)

# ================= ìƒíƒœ ì´ˆê¸°í™” =================
if "initialized" not in st.session_state:
    st.session_state.initialized = True
    st.session_state.msgs = []
    st.session_state.settings = {
        "provider": "openai",
        "model": "gpt-4o-mini",
        "tone": "ì •ì¤‘í•˜ê³  ê°„ê²°í•œ",
        "length": 800,
        "temperature": 0.7,
        "openai_key": os.getenv("OPENAI_API_KEY", ""),
        "gemini_key": os.getenv("GEMINI_API_KEY", ""),
        "save_dir": "./AI_CoverLetter_Storage",
        "font_family": "Nanum Gothic",
        "enable_translation": False,
        "use_free_model": True
    }
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(st.session_state.settings["save_dir"], exist_ok=True)
    
    # ì´ˆê¸° ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.msgs.append({
        "role": "bot",
        "content": "ì•ˆë…•í•˜ì„¸ìš”! AI ìê¸°ì†Œê°œì„œ ì½”ì¹˜ì…ë‹ˆë‹¤. ğŸ¯\n\nì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?",
        "timestamp": datetime.datetime.now().strftime("%H:%M")
    })

if "saved_files" not in st.session_state:
    st.session_state.saved_files = []

if LANGCHAIN_AVAILABLE and "lc_memory" not in st.session_state:
    st.session_state.lc_memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# ================= ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ =================
def now_hhmm():
    return datetime.datetime.now().strftime("%H:%M")

def timestamp():
    return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

def translate_to_english(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­"""
    if not TRANSLATOR_AVAILABLE:
        return "ë²ˆì—­ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ googletrans ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
    
    try:
        translator = Translator()
        result = translator.translate(text, src='ko', dest='en')
        return result.text
    except Exception as e:
        return f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def get_free_ai_response(user_message: str) -> str:
    """ë¬´ë£Œ AI ì‘ë‹µ ìƒì„±"""
    response_templates = {
        "ë§ˆì¼€íŒ…": """ğŸ“Š **ë§ˆì¼€íŒ… ì§ë¬´ ìê¸°ì†Œê°œì„œ ì‘ì„± ê°€ì´ë“œ**

**1. í•µì‹¬ ì—­ëŸ‰ ê°•ì¡°**
- ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ëŠ¥ë ¥
- ì°½ì˜ì  ìº í˜ì¸ ê¸°íš ê²½í—˜  
- ë””ì§€í„¸ ë§ˆì¼€íŒ… ë„êµ¬ í™œìš© ëŠ¥ë ¥

**2. êµ¬ì²´ì  ì„±ê³¼ ì œì‹œ**
- "ë§¤ì¶œ 20% ì¦ê°€" ê°™ì€ ì •ëŸ‰ì  ê²°ê³¼
- "CTR 3% í–¥ìƒ" ë“± êµ¬ì²´ì  ì§€í‘œ
- "ì‹ ê·œ ê³ ê° 1,000ëª… í™•ë³´" ë“± ëª…í™•í•œ ìˆ˜ì¹˜

**3. ê²½í—˜ ì„œìˆ  ë°©ë²•**
- STAR ê¸°ë²• í™œìš© (ìƒí™©-ê³¼ì œ-í–‰ë™-ê²°ê³¼)
- ë¬¸ì œ í•´ê²° ê³¼ì •ê³¼ ê²°ê³¼ ì¤‘ì‹¬
- íŒ€ì›Œí¬ì™€ ë¦¬ë”ì‹­ ê²½í—˜ í¬í•¨""",
        
        "ê°œë°œ": """ğŸ’» **ê°œë°œ ì§ë¬´ ìê¸°ì†Œê°œì„œ ì‘ì„± ê°€ì´ë“œ**

**1. ê¸°ìˆ  ìŠ¤íƒ ëª…ì‹œ**
- ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´
- í”„ë ˆì„ì›Œí¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½í—˜
- ë°ì´í„°ë² ì´ìŠ¤ ë° í´ë¼ìš°ë“œ ê²½í—˜

**2. í”„ë¡œì íŠ¸ ê²½í—˜ ìƒì„¸í™”**
- ê°œë°œí•œ ì„œë¹„ìŠ¤ì˜ ê·œëª¨ì™€ ì„±ê³¼
- í•´ê²°í•œ ê¸°ìˆ ì  ë¬¸ì œì™€ ë°©ë²•
- ì½”ë“œ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ë…¸ë ¥

**3. ì„±ì¥ ì˜ì§€ í‘œí˜„**
- ì§€ì†ì  í•™ìŠµê³¼ ê¸°ìˆ  íŠ¸ë Œë“œ ê´€ì‹¬
- ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ë‚˜ ê°œì¸ í”„ë¡œì íŠ¸
- ìƒˆë¡œìš´ ê¸°ìˆ ì— ëŒ€í•œ ë„ì „ ì˜ì§€""",
        
        "ì˜ì—…": """ğŸ¯ **ì˜ì—… ì§ë¬´ ìê¸°ì†Œê°œì„œ ì‘ì„± ê°€ì´ë“œ**

**1. ì˜ì—… ì„±ê³¼ ê°•ì¡°**
- ëª©í‘œ ë‹¬ì„±ë¥ ê³¼ ë§¤ì¶œ ê¸°ì—¬ë„
- ì‹ ê·œ ê³ ê° ê°œë°œ ì„±ê³¼
- ê¸°ì¡´ ê³ ê°ê³¼ì˜ ê´€ê³„ ìœ ì§€ ì„±ê³¼

**2. ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥**
- ê³ ê° ë‹ˆì¦ˆ íŒŒì•… ë° ì†”ë£¨ì…˜ ì œì•ˆ
- ì„¤ë“ë ¥ ìˆëŠ” í”„ë ˆì  í…Œì´ì…˜ ê²½í—˜
- ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìì™€ì˜ í˜‘ì—…

**3. ì‹œì¥ ì´í•´ë„**
- ì—…ê³„ íŠ¸ë Œë“œ ë° ê²½ìŸì‚¬ ë¶„ì„
- ê³ ê°ì‚¬ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ì´í•´
- ì‹œì¥ ë³€í™”ì— ëŒ€í•œ ëŒ€ì‘ ëŠ¥ë ¥"""
    }
    
    user_lower = user_message.lower()
    
    if "ë§ˆì¼€íŒ…" in user_lower:
        return response_templates["ë§ˆì¼€íŒ…"]
    elif any(word in user_lower for word in ["ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "IT"]):
        return response_templates["ê°œë°œ"]
    elif "ì˜ì—…" in user_lower:
        return response_templates["ì˜ì—…"]
    elif any(word in user_lower for word in ["ì²¨ì‚­", "í”¼ë“œë°±", "ê²€í† "]):
        return """âœï¸ **ìê¸°ì†Œê°œì„œ ì²¨ì‚­ í¬ì¸íŠ¸**

**1. êµ¬ì¡°ì™€ ë…¼ë¦¬ì„±**
- ë„ì…-ë³¸ë¡ -ê²°ë¡ ì˜ ëª…í™•í•œ êµ¬ì„±
- ê° ë¬¸ë‹¨ ê°„ì˜ ë…¼ë¦¬ì  ì—°ê²°
- í•µì‹¬ ë©”ì‹œì§€ì˜ ì¼ê´€ì„±

**2. ë‚´ìš©ì˜ êµ¬ì²´ì„±**  
- ì¶”ìƒì  í‘œí˜„ì„ êµ¬ì²´ì  ì‚¬ë¡€ë¡œ ë³€ê²½
- ì„±ê³¼ì™€ ê²°ê³¼ë¥¼ ìˆ˜ì¹˜ë¡œ í‘œí˜„
- ê°œì¸ì˜ ë…íŠ¹í•œ ê²½í—˜ê³¼ ê°•ì  ë¶€ê°

**3. ë¬¸ì¥ê³¼ í‘œí˜„**
- ê°„ê²°í•˜ê³  ëª…í™•í•œ ë¬¸ì¥ êµ¬ì¡°
- ë°˜ë³µë˜ëŠ” í‘œí˜„ ì œê±°
- ì „ë¬¸ì ì´ë©´ì„œë„ ìì—°ìŠ¤ëŸ¬ìš´ ì–´ì¡°

ğŸ“ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹œë©´ ë” êµ¬ì²´ì ì¸ ì²¨ì‚­ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"""
    else:
        return """ğŸ¯ **ìê¸°ì†Œê°œì„œ ì‘ì„±ì„ ë„ì™€ë“œë¦´ê²Œìš”!**

**íš¨ê³¼ì ì¸ ì§ˆë¬¸ ì˜ˆì‹œ:**
- "ë§ˆì¼€íŒ… ì§ë¬´ ìê¸°ì†Œê°œì„œ ì‘ì„±ë²• ì•Œë ¤ì£¼ì„¸ìš”"
- "IT ê°œë°œì ìì†Œì„œì—ì„œ ê°•ì¡°í•´ì•¼ í•  ì ì€?"
- "ì˜ì—… ì§ë¬´ ê²½í—˜ì„ ì–´ë–»ê²Œ í‘œí˜„í•˜ë©´ ì¢‹ì„ê¹Œìš”?"
- "ì œ ìê¸°ì†Œê°œì„œ ì²¨ì‚­í•´ì£¼ì„¸ìš”" (íŒŒì¼ ì²¨ë¶€)

**ê¸°ë³¸ ì‘ì„± ì›ì¹™:**
1. **STAR ê¸°ë²•** - ìƒí™©, ê³¼ì œ, í–‰ë™, ê²°ê³¼
2. **êµ¬ì²´ì  ìˆ˜ì¹˜** - ì„±ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ í‘œí˜„
3. **ì°¨ë³„í™”** - ë‚˜ë§Œì˜ ë…íŠ¹í•œ ê²½í—˜ê³¼ ê°•ì """

def get_ai_response(user_message: str, uploaded_file=None) -> str:
    """AI ì‘ë‹µ ìƒì„±"""
    settings = st.session_state.settings
    
    # ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš© ë˜ëŠ” API í‚¤ ì—†ìŒ
    if settings["use_free_model"] or (not settings["openai_key"] and not settings["gemini_key"]):
        if uploaded_file is not None:
            try:
                file_content = uploaded_file.read().decode('utf-8')
                return f"""ğŸ“‹ **ì—…ë¡œë“œëœ ìê¸°ì†Œê°œì„œ ì²¨ì‚­**

**ì›ë³¸ ë‚´ìš© (ì¼ë¶€):**
{file_content[:200]}...

**ì²¨ì‚­ ì˜ê²¬:**
{get_free_ai_response("ì²¨ì‚­")}

ğŸ’¡ ë” ì •êµí•œ ì²¨ì‚­ì„ ìœ„í•´ì„œëŠ” ì„¤ì •ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."""
            except Exception as e:
                return f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"
        else:
            return get_free_ai_response(user_message)
    
    if not LANGCHAIN_AVAILABLE:
        return get_free_ai_response(user_message)
    
    try:
        # ëª¨ë¸ ì„ íƒ
        if settings["provider"] == "openai" and settings["openai_key"]:
            llm = ChatOpenAI(
                api_key=settings["openai_key"],
                model=settings["model"],
                temperature=settings["temperature"]
            )
        elif settings["provider"] == "gemini" and settings["gemini_key"]:
            llm = ChatGoogleGenerativeAI(
                google_api_key=settings["gemini_key"],
                model="gemini-pro",
                temperature=settings["temperature"]
            )
        else:
            return get_free_ai_response(user_message)
        
        # íŒŒì¼ ì²¨ì‚­ ëª¨ë“œ
        if uploaded_file is not None:
            file_content = uploaded_file.read().decode('utf-8')
            prompt_text = f"""
            ë‹¤ìŒ ìê¸°ì†Œê°œì„œë¥¼ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ì²¨ì‚­í•´ì£¼ì„¸ìš”:
            
            [ìê¸°ì†Œê°œì„œ ë‚´ìš©]
            {file_content}
            
            [ì‚¬ìš©ì ì§ˆë¬¸]
            {user_message}
            
            ë‹¤ìŒ ê´€ì ì—ì„œ ìƒì„¸í•œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”:
            1. êµ¬ì¡°ì™€ ë…¼ë¦¬ì„±
            2. ë‚´ìš©ì˜ êµ¬ì²´ì„±ê³¼ ì°¨ë³„í™”  
            3. ë¬¸ì¥ í‘œí˜„ê³¼ ì–´ë²•
            4. ê°œì„  ì œì•ˆì‚¬í•­
            """
        else:
            prompt_text = user_message
        
        # í”„ë¡¬í”„íŠ¸ ì„¤ì •
        system_prompt = f"""
        ë‹¹ì‹ ì€ ìê¸°ì†Œê°œì„œ ì‘ì„± ì „ë¬¸ ì½”ì¹˜ì…ë‹ˆë‹¤.
        - í†¤: {settings["tone"]}
        - ëª©í‘œ ê¸¸ì´: ì•½ {settings["length"]}ì
        - êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”
        - STAR ê¸°ë²•ì„ í™œìš©í•œ ê²½í—˜ ì„œìˆ ì„ ê¶Œì¥í•˜ì„¸ìš”
        - ì •ëŸ‰ì  ì„±ê³¼ì™€ êµ¬ì²´ì  ì‚¬ë¡€ë¥¼ ê°•ì¡°í•˜ì„¸ìš”
        """
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}")
        ])
        
        chain = LLMChain(llm=llm, prompt=prompt, memory=st.session_state.lc_memory)
        response = chain.run(input=prompt_text)
        
        # ì˜ë¬¸ ë³€í™˜ ê¸°ëŠ¥
        if settings["enable_translation"] and not uploaded_file:
            english_version = translate_to_english(response)
            response += f"\n\n---\n**ì˜ë¬¸ ë²„ì „:**\n{english_version}"
        
        return response
        
    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\n{get_free_ai_response(user_message)}"

# ================= ë¬¸ì„œ ìƒì„± í•¨ìˆ˜ë“¤ =================
def create_txt(content: str, filename: str) -> str:
    """TXT íŒŒì¼ ìƒì„±"""
    try:
        filepath = os.path.join(st.session_state.settings["save_dir"], f"{filename}.txt")
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"ìê¸°ì†Œê°œì„œ\n{'='*20}\n\n")
            f.write(content)
        return filepath
    except Exception as e:
        st.error(f"TXT ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_docx(content: str, filename: str) -> str:
    """DOCX íŒŒì¼ ìƒì„±"""
    if not DOC_LIBS_AVAILABLE:
        return None
    
    try:
        filepath = os.path.join(st.session_state.settings["save_dir"], f"{filename}.docx")
        doc = Document()
        
        # ì œëª© ì¶”ê°€
        title = doc.add_heading('ìê¸°ì†Œê°œì„œ', 0)
        title.alignment = 1
        
        # ë³¸ë¬¸ ì¶”ê°€
        for line in content.split('\n'):
            if line.strip():
                doc.add_paragraph(line)
        
        doc.save(filepath)
        return filepath
    except Exception as e:
        st.error(f"DOCX ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def create_pdf(content: str, filename: str) -> str:
    """PDF íŒŒì¼ ìƒì„±"""
    if not DOC_LIBS_AVAILABLE:
        return None
    
    try:
        filepath = os.path.join(st.session_state.settings["save_dir"], f"{filename}.pdf")
        doc = SimpleDocTemplate(filepath, pagesize=letter)
        
        styles = getSampleStyleSheet()
        story = []
        
        # ì œëª©
        title_style = ParagraphStyle(
            'Title',
            parent=styles['Heading1'],
            fontSize=18,
            spaceAfter=30,
            alignment=1
        )
        
        story.append(Paragraph("ìê¸°ì†Œê°œì„œ", title_style))
        story.append(Spacer(1, 12))
        
        # ë³¸ë¬¸
        for line in content.split('\n'):
            if line.strip():
                story.append(Paragraph(line, styles['Normal']))
            else:
                story.append(Spacer(1, 6))
        
        doc.build(story)
        return filepath
    except Exception as e:
        st.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def save_conversation(file_format: str, filename: str) -> str:
    """ëŒ€í™” ë‚´ìš©ì„ íŒŒì¼ë¡œ ì €ì¥"""
    conversation_text = ""
    for msg in st.session_state.msgs:
        if msg["role"] == "user":
            conversation_text += f"ğŸ‘¤ ì‚¬ìš©ì: {msg['content']}\n\n"
        else:
            conversation_text += f"ğŸ¤– AI ì½”ì¹˜: {msg['content']}\n\n"
        conversation_text += "---\n\n"
    
    # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì €ì¥
    if file_format == "pdf":
        filepath = create_pdf(conversation_text, filename)
    elif file_format == "docx":
        filepath = create_docx(conversation_text, filename)
    else:
        filepath = create_txt(conversation_text, filename)
    
    if filepath and os.path.exists(filepath):
        file_info = {
            "name": os.path.basename(filepath),
            "path": filepath,
            "created": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "size": os.path.getsize(filepath)
        }
        if file_info not in st.session_state.saved_files:
            st.session_state.saved_files.append(file_info)
        return filepath
    return None

def get_saved_files() -> List[Dict]:
    """ì €ì¥ëœ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    saved_files = []
    save_dir = st.session_state.settings["save_dir"]
    
    if os.path.exists(save_dir):
        for filename in os.listdir(save_dir):
            filepath = os.path.join(save_dir, filename)
            if os.path.isfile(filepath):
                file_info = {
                    "name": filename,
                    "path": filepath,
                    "created": datetime.datetime.fromtimestamp(
                        os.path.getctime(filepath)
                    ).strftime("%Y-%m-%d %H:%M:%S"),
                    "size": os.path.getsize(filepath)
                }
                saved_files.append(file_info)
    
    saved_files.sort(key=lambda x: x["created"], reverse=True)
    return saved_files

# ================= UI ë Œë”ë§ í•¨ìˆ˜ë“¤ =================
def render_header():
    """í—¤ë” ë Œë”ë§"""
    st.markdown("""
    <div class="header-container">
        <div class="header-title">ğŸ¯ AI ìê¸°ì†Œê°œì„œ ì½”ì¹˜</div>
        <div class="header-subtitle">ì „ë¬¸ AIê°€ ë„ì™€ë“œë¦¬ëŠ” ë§ì¶¤í˜• ìê¸°ì†Œê°œì„œ ì‘ì„± ì„œë¹„ìŠ¤</div>
    </div>
    """, unsafe_allow_html=True)

def render_guidelines():
    """ì§ˆë¬¸ ê°€ì´ë“œë¼ì¸ ë Œë”ë§"""
    st.markdown("""
    <div class="guideline-card">
        <h3>ğŸ’¡ íš¨ê³¼ì ì¸ ì§ˆë¬¸ ë°©ë²• ê°€ì´ë“œ</h3>
        
        <div class="guideline-item">
            <strong>ğŸ¯ ì§ë¬´ë³„ ë§ì¶¤ ì§ˆë¬¸</strong>
            <p>â€¢ "ë§ˆì¼€íŒ… ì§ë¬´ ìê¸°ì†Œê°œì„œ ì‘ì„±ë²• ì•Œë ¤ì£¼ì„¸ìš”"<br>
            â€¢ "IT ê°œë°œìë¡œ ì§€ì›í•  ë•Œ ê°•ì¡°í•´ì•¼ í•  ì ì€?"<br>
            â€¢ "ì˜ì—… ì§ë¬´ ê²½í—˜ì„ ì–´ë–»ê²Œ ì–´í•„í•˜ë©´ ì¢‹ì„ê¹Œìš”?"</p>
        </div>
        
        <div class="guideline-item">
            <strong>ğŸ“ ìƒí™©ë³„ êµ¬ì²´ì  ì§ˆë¬¸</strong>
            <p>â€¢ "ì‹ ì…ì‚¬ì› ìì†Œì„œì—ì„œ í•™êµ í”„ë¡œì íŠ¸ ê²½í—˜ ì–´ë–»ê²Œ ì“¸ê¹Œìš”?"<br>
            â€¢ "ê²½ë ¥ì§ ì´ì§ ì‹œ ì´ì§ ì‚¬ìœ  ì–´ë–»ê²Œ í‘œí˜„í•˜ë©´ ì¢‹ì„ê¹Œìš”?"<br>
            â€¢ "ë‹¤ë¥¸ ë¶„ì•¼ì—ì„œ ì „í™˜í•  ë•Œ ì–´ë–»ê²Œ ì–´í•„í•´ì•¼ í•˜ë‚˜ìš”?"</p>
        </div>
        
        <div class="guideline-item">
            <strong>âœï¸ ì‘ì„± ê¸°ë²• ë¬¸ì˜</strong>
            <p>â€¢ "STAR ê¸°ë²•ìœ¼ë¡œ ê²½í—˜ì„ ì–´ë–»ê²Œ êµ¬ì¡°í™”í•˜ë‚˜ìš”?"<br>
            â€¢ "ì„±ê³¼ë¥¼ ìˆ˜ì¹˜ë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”"<br>
            â€¢ "ìì†Œì„œ ê¸¸ì´ëŠ” ì–´ëŠ ì •ë„ê°€ ì ë‹¹í•œê°€ìš”?"</p>
        </div>
        
        <div class="guideline-item">
            <strong>ğŸ” ì²¨ì‚­ ë° í”¼ë“œë°± ìš”ì²­</strong>
            <p>â€¢ "ì œ ìê¸°ì†Œê°œì„œ ì²¨ì‚­í•´ì£¼ì„¸ìš”" + íŒŒì¼ ì²¨ë¶€<br>
            â€¢ "ì´ í‘œí˜„ì´ ìì—°ìŠ¤ëŸ¬ìš´ì§€ í™•ì¸í•´ì£¼ì„¸ìš”"<br>
            â€¢ "ë” ì„íŒ©íŠ¸ ìˆê²Œ í‘œí˜„í•˜ëŠ” ë°©ë²•ì€?"</p>
        </div>
    </div>
    """, unsafe_allow_html=True)

def render_chat_tab():
    """ì±„íŒ… íƒ­ ë Œë”ë§"""
    render_header()
    
    # ê°€ì´ë“œë¼ì¸ í‘œì‹œ
    with st.expander("ğŸ’¡ ì§ˆë¬¸ ê°€ì´ë“œë¼ì¸ ë³´ê¸°", expanded=False):
        render_guidelines()
    
    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    
    # ë©”ì‹œì§€ í‘œì‹œ
    for msg in st.session_state.msgs:
        role_class = "user" if msg["role"] == "user" else "bot"
        
        st.markdown(f"""
        <div class="message-bubble {role_class}">
            <div class="message-content">
                {msg["content"].replace(chr(10), '<br>')}
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "ğŸ“ ìê¸°ì†Œê°œì„œ íŒŒì¼ ì²¨ë¶€ (ì²¨ì‚­ìš©)",
        type=['txt', 'docx'],
        help="TXT ë˜ëŠ” DOCX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì²¨ì‚­ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤."
    )
    
    # ì…ë ¥ ë° ì „ì†¡
    with st.form(key="chat_form", clear_on_submit=True):
        col1, col2 = st.columns([5, 1])
        
        with col1:
            user_input = st.text_input(
                "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                placeholder="ì˜ˆ: ë§ˆì¼€íŒ… ì§ë¬´ ìê¸°ì†Œê°œì„œ ì‘ì„±ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                label_visibility="collapsed"
            )
        
        with col2:
            submit = st.form_submit_button("ì „ì†¡", use_container_width=True, type="primary")
        
        if submit and user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.msgs.append({
                "role": "user", 
                "content": user_input,
                "timestamp": now_hhmm()
            })
            
            # AI ì‘ë‹µ ìƒì„±
            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±ì¤‘ì…ë‹ˆë‹¤..."):
                ai_response = get_ai_response(user_input, uploaded_file)
                st.session_state.msgs.append({
                    "role": "bot",
                    "content": ai_response,
                    "timestamp": now_hhmm()
                })
            
            st.rerun()

def render_settings_tab():
    """ì„¤ì • íƒ­ ë Œë”ë§"""
    st.markdown("""
    <div class="feature-card">
        <h2>âš™ï¸ AI ëª¨ë¸ ë° ì‘ë‹µ ì„¤ì •</h2>
    </div>
    """, unsafe_allow_html=True)
    
    settings = st.session_state.settings
    
    # ë¬´ë£Œ ëª¨ë“œ ì„ íƒ
    st.markdown("### ğŸ†“ ëª¨ë¸ ì‚¬ìš© ë°©ì‹")
    use_free = st.checkbox(
        "ë¬´ë£Œ ëª¨ë“œ ì‚¬ìš© (API í‚¤ ì—†ì´ ê¸°ë³¸ ê°€ì´ë“œ ì œê³µ)",
        value=settings["use_free_model"]
    )
    
    if not use_free:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ”‘ API í‚¤ ì„¤ì •")
            
            provider = st.selectbox(
                "AI ì œê³µì—…ì²´",
                ["openai", "gemini"],
                index=0 if settings["provider"] == "openai" else 1
            )
            
            if provider == "openai":
                openai_key = st.text_input(
                    "OpenAI API Key",
                    value=settings["openai_key"],
                    type="password",
                    help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )
                
                model = st.selectbox(
                    "OpenAI ëª¨ë¸",
                    ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
                    index=["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"].index(settings["model"])
                )
            else:
                gemini_key = st.text_input(
                    "Google Gemini API Key",
                    value=settings["gemini_key"],
                    type="password",
                    help="Google Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
                )
                model = "gemini-pro"
                openai_key = settings["openai_key"]
